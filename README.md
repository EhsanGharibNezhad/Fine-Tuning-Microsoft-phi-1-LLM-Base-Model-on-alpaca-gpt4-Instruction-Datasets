# Project: Fine-Tuning Microsoft/phi-1 LLM Base Model on alpaca-gpt4 Instruction Datasets (link)

Key steps:
- Utilized PEFT/LoRA techniques for fine-tuning the Microsoft/phi-1_5 pre-trained model on alpaca-gpt4 datasets.

- Leveraged advanced training approaches to refine the model's capabilities, aiming for improved precision, recall,
and other relevant metrics.

![image](LoRA_overview.jpg)
